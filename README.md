# Credit Risk Modeling â€“ End-to-End Machine Learning Project

## ğŸ“Œ Project Overview

This project demonstrates an **end-to-end credit risk modeling workflow** focused on **model development, validation, and analysis**, following practices commonly used in **real-world credit risk modeling**.

The objective is to estimate the **probability of default (PD)** for loan applicants. The project currently supports **offline scoring**: given a prepared input dataset, the model applies the same preprocessing steps and produces a risk score.

---

## ğŸ¯ Key Objectives

* Build credit risk models using **XGBoost, LightGBM, and CatBoost**
* Explicitly test **class imbalance handling** and make data-driven model choices
* Evaluate models using **KS as the primary performance metric**
* Perform disciplined **DEVâ€“VALâ€“TEST** based model selection
* Validate **rank ordering** using decile / gains analysis
* Analyze **feature importance and Information Value (IV)** for interpretability
* Persist final models and scored datasets for reproducibility

---

## ğŸ§± Project Structure

```
credit-risk/
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ credit_risk_scored_dataset.csv
â”‚   â”œâ”€â”€ model_dataset_with_sampling.csv      # DEV / VAL / TEST flagged dataset
â”‚   â”œâ”€â”€ model_Results.xlsx                   # Model results & comparisons
â”‚
â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ pre_processing.ipynb                 # Data cleaning, encoding, feature engineering
â”‚   â”œâ”€â”€ training.ipynb                       # Model training & hyperparameter tuning
â”‚   â”œâ”€â”€ model_results.ipynb                  # Model comparison, validation & analysis
â”‚   â”œâ”€â”€ utils.py                             # KS, IV, scoring utilities
â”‚
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ catboost_model.cbm                   # Final selected model
â”‚   â”œâ”€â”€ lightgbm_model.pkl                   # Challenger model
â”‚   â”œâ”€â”€ xgboost_model.pkl                    # Challenger model
â”‚
â”œâ”€â”€ credit_risk_env.yml                      # Conda environment
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```

---

## ğŸ“Š Dataset & Target

* **Target Variable:** `target_default` (1 = default, 0 = non-default)
* **Sampling Strategy:** Explicit split into

  * `DEV` â€“ model development & tuning
  * `VAL` â€“ model validation
  * `TEST` â€“ final unbiased evaluation

---

## âš™ï¸ Modeling Approach

### Models Trained

* XGBoost
* LightGBM
* CatBoost

Class imbalance was explicitly tested using model-specific weighting strategies (e.g., `scale_pos_weight`, `class_weight`, `auto_class_weights`). However, **unweighted models consistently demonstrated better validation KS and stability**. Therefore, unweighted models were selected based on empirical performance.

### Hyperparameter Tuning Strategy

* Manual grid search
* Models trained **only on DEV**
* Model selection based on:

  * **Validation KS**
  * **KS Gap (DEV âˆ’ VAL)**
* No re-tuning after observing TEST performance

This approach mirrors practical credit risk development workflows.

---

## ğŸ† Model Selection Results

### Final Performance (Frozen Models)

| Model                         | DEV_KS    | VAL_KS    | TEST_KS   |
| ----------------------------- | --------- | --------- | --------- |
| XGBoost                       | 38.45     | 33.21     | 31.31     |
| LightGBM                      | 40.85     | 33.00     | 31.35     |
| **CatBoost (Selected Model)** | **36.99** | **33.36** | **31.80** |

**CatBoost** was selected as the final model due to:

* Highest validation and test KS
* Lowest overfitting (stable KS gap)
* Consistent generalization across DEV, VAL, and TEST

Detailed model results are documented in the **model results Excel file**.

---

## ğŸ“ˆ Rank Ordering Validation (Decile / Gains Analysis)

* Deciles created on **DEV, VAL, TEST datasets** using predicted PD scores
* Strong monotonic increase in bad rates from lowest to highest risk deciles


This confirms the model is **cut-off ready** for risk-based decisioning.

---

## ğŸ” Stability Considerations

Basic stability checks were performed across DEV, VAL, and TEST samples. Given that datasets were generated using controlled sampling with identical target rates, no material population shift was observed during development.

---

## ğŸ§  Feature Analysis

### Feature Importance

* Model-based feature importance was extracted from CatBoost
* Importance reflects **multivariate contribution** and interaction effects

### Information Value (IV)

* IV was computed on the DEV dataset
* IV was used to assess **univariate predictive strength**
* No features exhibited abnormally high IV values indicative of leakage

> Note: Full **model explainability** using SHAP or local explanation techniques has not yet been implemented and is planned as a future extension.

---

## ğŸ’¾ Model Persistence & Reproducibility

* Final models are saved for **offline scoring and analysis**
* Scored datasets are exported to CSV for downstream evaluation
* Conda environment is captured via `credit_risk_env.yml`

This ensures reproducibility of results within the scope of this project.

---

## ğŸ› ï¸ Utilities

Key custom utilities implemented in `utils.py`:

* KS calculation
* KS scorer for model selection
* Information Value (IV) computation

---

## ğŸ“Œ Key Learnings

* Validation and stability matter more than raw performance
* ML-based credit models rely heavily on **feature interactions**
* Proper DEVâ€“VALâ€“TEST discipline is critical to avoid leakage
* Explainability and governance are essential for real-world deployment

---

## ğŸ“„ Disclaimer

This project is for **educational and portfolio purposes only** and does not represent a production credit decisioning system.

---

## ğŸ‘¤ Author

**Rudhvi Uggirala**
Data Scientist â€“ Risk & Credit Analytics